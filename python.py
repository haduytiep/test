# python.py
import streamlit as st
import pandas as pd
from google import genai
from google.genai.errors import APIError

# --- C·∫•u h√¨nh Trang Streamlit ---
st.set_page_config(
    page_title="App Ph√¢n T√≠ch B√°o C√°o T√†i Ch√≠nh",
    layout="wide"
)

st.title("·ª®ng d·ª•ng Ph√¢n T√≠ch B√°o C√°o T√†i Ch√≠nh üìä")

# =========================
#   KHU V·ª∞C C·∫§U H√åNH CHUNG
# =========================
with st.sidebar:
    st.subheader("üîë C·∫•u h√¨nh AI")
    # ∆Øu ti√™n l·∫•y t·ª´ secrets; n·∫øu kh√¥ng c√≥ th√¨ cho ph√©p nh·∫≠p tay
    default_api_key = st.secrets.get("GEMINI_API_KEY", "")
    api_key_input = st.text_input(
        "GEMINI_API_KEY (∆∞u ti√™n l·∫•y t·ª´ Secrets, c√≥ th·ªÉ nh·∫≠p t·∫°m ·ªü ƒë√¢y)",
        type="password",
        value="" if default_api_key else "",
        help="ƒê·ªÉ an to√†n, n√™n c·∫•u h√¨nh trong Secrets c·ªßa Streamlit Cloud."
    )
    active_api_key = default_api_key or api_key_input

    model_name = st.selectbox(
        "Model Gemini",
        options=[
            "gemini-2.5-flash",
            "gemini-2.0-flash",
            "gemini-2.0-pro"
        ],
        index=0
    )
    temperature = st.slider("Temperature", 0.0, 1.0, 0.4, 0.1)
    attach_df_to_chat = st.checkbox(
        "ƒê√≠nh k√®m b·∫£ng ph√¢n t√≠ch (n·∫øu c√≥) v√†o ng·ªØ c·∫£nh Chat",
        value=True
    )

# =========================
#   C√ÅC H√ÄM X·ª¨ L√ù HI·ªÜN C√ì
# =========================
@st.cache_data
def process_financial_data(df):
    """Th·ª±c hi·ªán c√°c ph√©p t√≠nh TƒÉng tr∆∞·ªüng v√† T·ª∑ tr·ªçng."""
    # ƒê·∫£m b·∫£o c√°c gi√° tr·ªã l√† s·ªë ƒë·ªÉ t√≠nh to√°n
    numeric_cols = ['NƒÉm tr∆∞·ªõc', 'NƒÉm sau']
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # 1. T√≠nh T·ªëc ƒë·ªô TƒÉng tr∆∞·ªüng
    df['T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)'] = (
        (df['NƒÉm sau'] - df['NƒÉm tr∆∞·ªõc']) / df['NƒÉm tr∆∞·ªõc'].replace(0, 1e-9)
    ) * 100

    # 2. T√≠nh T·ª∑ tr·ªçng theo T·ªïng T√†i s·∫£n
    tong_tai_san_row = df[df['Ch·ªâ ti√™u'].str.contains('T·ªîNG C·ªòNG T√ÄI S·∫¢N', case=False, na=False)]
    if tong_tai_san_row.empty:
        raise ValueError("Kh√¥ng t√¨m th·∫•y ch·ªâ ti√™u 'T·ªîNG C·ªòNG T√ÄI S·∫¢N'.")

    tong_tai_san_N_1 = tong_tai_san_row['NƒÉm tr∆∞·ªõc'].iloc[0]
    tong_tai_san_N = tong_tai_san_row['NƒÉm sau'].iloc[0]

    # S·ª≠a l·ªói chia 0 ·ªü gi√° tr·ªã ƒë∆°n l·∫ª
    divisor_N_1 = tong_tai_san_N_1 if tong_tai_san_N_1 != 0 else 1e-9
    divisor_N = tong_tai_san_N if tong_tai_san_N != 0 else 1e-9

    # T√≠nh t·ª∑ tr·ªçng
    df['T·ª∑ tr·ªçng NƒÉm tr∆∞·ªõc (%)'] = (df['NƒÉm tr∆∞·ªõc'] / divisor_N_1) * 100
    df['T·ª∑ tr·ªçng NƒÉm sau (%)'] = (df['NƒÉm sau'] / divisor_N) * 100

    return df

def get_ai_analysis(data_for_ai, api_key, model="gemini-2.5-flash", temperature=0.4):
    """G·ª≠i d·ªØ li·ªáu ph√¢n t√≠ch ƒë·∫øn Gemini API v√† nh·∫≠n nh·∫≠n x√©t."""
    try:
        client = genai.Client(api_key=api_key)
        prompt = f"""
B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch t√†i ch√≠nh chuy√™n nghi·ªáp. D·ª±a tr√™n c√°c ch·ªâ s·ªë t√†i ch√≠nh sau, h√£y ƒë∆∞a ra nh·∫≠n x√©t kh√°ch quan, ng·∫Øn g·ªçn (3‚Äì4 ƒëo·∫°n) v·ªÅ t√¨nh h√¨nh t√†i ch√≠nh c·ªßa doanh nghi·ªáp. 
T·∫≠p trung v√†o: (1) t·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng, (2) thay ƒë·ªïi c∆° c·∫•u t√†i s·∫£n, (3) kh·∫£ nƒÉng thanh to√°n hi·ªán h√†nh. 
Tr√¨nh b√†y r√µ r√†ng, c√≥ g·∫°ch ƒë·∫ßu d√≤ng khi c·∫ßn.

D·ªØ li·ªáu (markdown):
{data_for_ai}
"""
        response = client.models.generate_content(
            model=model,
            contents=prompt,
            config={"temperature": temperature}
        )
        return getattr(response, "text", "").strip() or "Kh√¥ng nh·∫≠n ƒë∆∞·ª£c n·ªôi dung ph·∫£n h·ªìi t·ª´ m√¥ h√¨nh."
    except APIError as e:
        return f"L·ªói g·ªçi Gemini API: Vui l√≤ng ki·ªÉm tra Kh√≥a API ho·∫∑c gi·ªõi h·∫°n s·ª≠ d·ª•ng. Chi ti·∫øt l·ªói: {e}"
    except KeyError:
        return "L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API 'GEMINI_API_KEY'. Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh Secrets."
    except Exception as e:
        return f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"

# =========================
#       GIAO DI·ªÜN CH√çNH
# =========================
tab_phan_tich, tab_chat = st.tabs(["üìà Ph√¢n t√≠ch b√°o c√°o", "üí¨ Chat Q&A v·ªõi Gemini"])

with tab_phan_tich:
    # --- Ch·ª©c nƒÉng 1: T·∫£i File ---
    uploaded_file = st.file_uploader(
        "1. T·∫£i file Excel B√°o c√°o T√†i ch√≠nh (Ch·ªâ ti√™u | NƒÉm tr∆∞·ªõc | NƒÉm sau)",
        type=['xlsx', 'xls']
    )

    if uploaded_file is not None:
        try:
            df_raw = pd.read_excel(uploaded_file)

            # Ti·ªÅn x·ª≠ l√Ω: ƒê·∫£m b·∫£o ch·ªâ c√≥ 3 c·ªôt quan tr·ªçng
            df_raw.columns = ['Ch·ªâ ti√™u', 'NƒÉm tr∆∞·ªõc', 'NƒÉm sau']

            # X·ª≠ l√Ω d·ªØ li·ªáu
            df_processed = process_financial_data(df_raw.copy())

            if df_processed is not None:
                # --- Ch·ª©c nƒÉng 2 & 3: Hi·ªÉn th·ªã K·∫øt qu·∫£ ---
                st.subheader("2. T·ªëc ƒë·ªô TƒÉng tr∆∞·ªüng & 3. T·ª∑ tr·ªçng C∆° c·∫•u T√†i s·∫£n")
                st.dataframe(
                    df_processed.style.format({
                        'NƒÉm tr∆∞·ªõc': '{:,.0f}',
                        'NƒÉm sau': '{:,.0f}',
                        'T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)': '{:.2f}%',
                        'T·ª∑ tr·ªçng NƒÉm tr∆∞·ªõc (%)': '{:.2f}%',
                        'T·ª∑ tr·ªçng NƒÉm sau (%)': '{:.2f}%'
                    }), use_container_width=True
                )

                # --- Ch·ª©c nƒÉng 4: T√≠nh Ch·ªâ s·ªë T√†i ch√≠nh ---
                st.subheader("4. C√°c Ch·ªâ s·ªë T√†i ch√≠nh C∆° b·∫£n")
                try:
                    # L·∫•y T√†i s·∫£n ng·∫Øn h·∫°n
                    tsnh_n = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm sau'].iloc[0]
                    tsnh_n_1 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm tr∆∞·ªõc'].iloc[0]

                    # L·∫•y N·ª£ ng·∫Øn h·∫°n
                    no_ngan_han_N = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('N·ª¢ NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm sau'].iloc[0]
                    no_ngan_han_N_1 = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('N·ª¢ NG·∫ÆN H·∫†N', case=False, na=False)]['NƒÉm tr∆∞·ªõc'].iloc[0]

                    # T√≠nh to√°n
                    thanh_toan_hien_hanh_N = tsnh_n / no_ngan_han_N if no_ngan_han_N != 0 else float("inf")
                    thanh_toan_hien_hanh_N_1 = tsnh_n_1 / no_ngan_han_han_N_1 if no_ngan_han_N_1 != 0 else float("inf")

                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric(
                            label="Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh (NƒÉm tr∆∞·ªõc)",
                            value=f"{thanh_toan_hien_hanh_N_1:.2f} l·∫ßn"
                        )
                    with col2:
                        delta_val = (
                            thanh_toan_hien_hanh_N - thanh_toan_hien_hanh_N_1
                            if not (pd.isna(thanh_toan_hien_hanh_N) or pd.isna(thanh_toan_hien_hanh_N_1))
                            else 0
                        )
                        st.metric(
                            label="Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh (NƒÉm sau)",
                            value=f"{thanh_toan_hien_hanh_N:.2f} l·∫ßn",
                            delta=f"{delta_val:.2f}"
                        )

                except IndexError:
                    st.warning("Thi·∫øu ch·ªâ ti√™u 'T√ÄI S·∫¢N NG·∫ÆN H·∫†N' ho·∫∑c 'N·ª¢ NG·∫ÆN H·∫†N' ƒë·ªÉ t√≠nh ch·ªâ s·ªë.")
                    thanh_toan_hien_hanh_N = "N/A"
                    thanh_toan_hien_hanh_N_1 = "N/A"

                # --- Ch·ª©c nƒÉng 5: Nh·∫≠n x√©t AI ---
                st.subheader("5. Nh·∫≠n x√©t T√¨nh h√¨nh T√†i ch√≠nh (AI)")

                data_for_ai = pd.DataFrame({
                    'Ch·ªâ ti√™u': [
                        'To√†n b·ªô B·∫£ng ph√¢n t√≠ch (d·ªØ li·ªáu th√¥)',
                        'TƒÉng tr∆∞·ªüng T√†i s·∫£n ng·∫Øn h·∫°n (%)',
                        'Thanh to√°n hi·ªán h√†nh (N-1)',
                        'Thanh to√°n hi·ªán h√†nh (N)'
                    ],
                    'Gi√° tr·ªã': [
                        df_processed.to_markdown(index=False),
                        (
                            f"{df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]['T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)'].iloc[0]:.2f}%"
                            if (df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)).any()
                            else "N/A"
                        ),
                        f"{thanh_toan_hien_hanh_N_1}",
                        f"{thanh_toan_hien_hanh_N}"
                    ]
                }).to_markdown(index=False)

                if st.button("Y√™u c·∫ßu AI Ph√¢n t√≠ch"):
                    if active_api_key:
                        with st.spinner('ƒêang g·ª≠i d·ªØ li·ªáu v√† ch·ªù Gemini ph√¢n t√≠ch...'):
                            ai_result = get_ai_analysis(
                                data_for_ai,
                                api_key=active_api_key,
                                model=model_name,
                                temperature=temperature
                            )
                            st.markdown("**K·∫øt qu·∫£ Ph√¢n t√≠ch t·ª´ Gemini AI:**")
                            st.info(ai_result)
                    else:
                        st.error("L·ªói: Ch∆∞a c√≥ GEMINI_API_KEY. H√£y c·∫•u h√¨nh trong Secrets ho·∫∑c nh·∫≠p t·∫°m ·ªü Sidebar.")

        except ValueError as ve:
            st.error(f"L·ªói c·∫•u tr√∫c d·ªØ li·ªáu: {ve}")
        except Exception as e:
            st.error(f"C√≥ l·ªói x·∫£y ra khi ƒë·ªçc ho·∫∑c x·ª≠ l√Ω file: {e}. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng file.")
    else:
        st.info("Vui l√≤ng t·∫£i l√™n file Excel ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")

# =========================
#     TAB 2: CHAT V·ªöI GEMINI
# =========================
with tab_chat:
    st.markdown("### üí¨ Chat h·ªèi‚Äìƒë√°p v·ªõi Gemini")
    st.caption("G·ª£i √Ω: B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ ph√¢n t√≠ch b√°o c√°o, gi·∫£i th√≠ch ch·ªâ s·ªë, so s√°nh nƒÉm, ho·∫∑c ƒë∆∞a c√¢u h·ªèi t·ª± do.")

    # Kh·ªüi t·∫°o l·ªãch s·ª≠ chat
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []  # m·ªói ph·∫ßn t·ª≠: {"role": "user"/"assistant", "content": "..."}

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # √î nh·∫≠p chat
    user_prompt = st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n b·∫±ng ti·∫øng Vi·ªát...")

    # L·∫•y dataframe ƒë√£ x·ª≠ l√Ω t·ª´ tab ph√¢n t√≠ch (n·∫øu c√≥) ƒë·ªÉ g·∫Øn v√†o ng·ªØ c·∫£nh chat
    df_for_context = None
    try:
        # N·∫øu ng∆∞·ªùi d√πng t·ª´ng t·∫£i file v√† df_processed c√≤n trong b·ªô nh·ªõ c·ªßa cache,
        # ta kh√¥ng th·ªÉ truy ƒë∆∞·ª£c tr·ª±c ti·∫øp bi·∫øn c·ª•c b·ªô. V√¨ v·∫≠y, k√™nh chat s·∫Ω ch·ªâ
        # ƒë√≠nh k√®m d·ªØ li·ªáu n·∫øu ng∆∞·ªùi d√πng ƒëang m·ªü c√πng phi√™n v√† bi·∫øn c√≤n trong scope.
        # C√°ch an to√†n h∆°n l√† l∆∞u v√†o session_state khi x·ª≠ l√Ω xong ·ªü tab ph√¢n t√≠ch:
        pass
    except Exception:
        pass

    # G·ª£i √Ω: ƒë·ªÉ lu√¥n c√≥ s·∫µn b·∫£ng cho chat, ta l∆∞u v√†o session_state khi x·ª≠ l√Ω xong:
    # (H√£y th√™m 2 d√≤ng d∆∞·ªõi ƒë√¢y v√†o ngay sau khi t·∫°o df_processed trong tab_phan_tich)
    # st.session_state["last_df_processed"] = df_processed
    # st.session_state["last_ai_metrics"] = {"tt_hien_hanh_N": thanh_toan_hien_hanh_N, "tt_hien_hanh_N_1": thanh_toan_hien_hanh_N_1}

    # X·ª≠ l√Ω khi ng∆∞·ªùi d√πng g·ª≠i chat
    if user_prompt is not None and user_prompt.strip():
        # Th√™m message ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
        st.session_state.chat_history.append({"role": "user", "content": user_prompt})
        with st.chat_message("user"):
            st.markdown(user_prompt)

        # Chu·∫©n b·ªã ng·ªØ c·∫£nh (history r√∫t g·ªçn + d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω n·∫øu c√≥)
        # L·∫•y t·ªëi ƒëa 8 l∆∞·ª£t g·∫ßn nh·∫•t ƒë·ªÉ g·ªçn prompt
        history_text_blocks = []
        for m in st.session_state.chat_history[-8:]:
            speaker = "Ng∆∞·ªùi d√πng" if m["role"] == "user" else "Tr·ª£ l√Ω"
            history_text_blocks.append(f"{speaker}: {m['content']}")
        history_text = "\n".join(history_text_blocks)

        df_markdown = ""
        if attach_df_to_chat and "last_df_processed" in st.session_state:
            try:
                df_markdown = st.session_state["last_df_processed"].to_markdown(index=False)
            except Exception:
                df_markdown = ""

        system_preamble = f"""
B·∫°n l√† tr·ª£ l√Ω t√†i ch√≠nh n√≥i ti·∫øng Vi·ªát, gi·∫£i th√≠ch ng·∫Øn g·ªçn, ch√≠nh x√°c, c√≥ th·ªÉ k√®m v√≠ d·ª• v√† c√¥ng th·ª©c n·∫øu ph√π h·ª£p. 
N·∫øu ng∆∞·ªùi d√πng h·ªèi ngo√†i lƒ©nh v·ª±c t√†i ch√≠nh, v·∫´n tr·∫£ l·ªùi l·ªãch s·ª± v√† r√µ r√†ng.
"""
        composite_prompt = f"""{system_preamble}

L·ªãch s·ª≠ h·ªôi tho·∫°i g·∫ßn nh·∫•t:
{history_text}

D·ªØ li·ªáu b·∫£ng (n·∫øu c√≥):
{df_markdown if df_markdown else "(kh√¥ng c√≥ b·∫£ng ƒë√≠nh k√®m)"}

C√¢u h·ªèi m·ªõi c·ªßa ng∆∞·ªùi d√πng:
{user_prompt}

H√£y tr·∫£ l·ªùi m·∫°ch l·∫°c, c√≥ g·∫°ch ƒë·∫ßu d√≤ng khi c·∫ßn, h·∫°n ch·∫ø l·∫∑p l·∫°i d·ªØ li·ªáu th√¥ d√†i d√≤ng.
"""

        # G·ªçi Gemini
        if not active_api_key:
            bot_answer = "L·ªói: Ch∆∞a c√≥ GEMINI_API_KEY. H√£y c·∫•u h√¨nh trong Secrets ho·∫∑c nh·∫≠p t·∫°m ·ªü Sidebar."
        else:
            try:
                client = genai.Client(api_key=active_api_key)
                resp = client.models.generate_content(
                    model=model_name,
                    contents=composite_prompt,
                    config={"temperature": temperature}
                )
                bot_answer = getattr(resp, "text", "").strip() or "M√¨nh ch∆∞a nh·∫≠n ƒë∆∞·ª£c n·ªôi dung tr·∫£ l·ªùi t·ª´ m√¥ h√¨nh."
            except APIError as e:
                bot_answer = f"L·ªói g·ªçi Gemini API: {e}"
            except Exception as e:
                bot_answer = f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"

        # Hi·ªÉn th·ªã & l∆∞u tin nh·∫Øn c·ªßa tr·ª£ l√Ω
        with st.chat_message("assistant"):
            st.markdown(bot_answer)
        st.session_state.chat_history.append({"role": "assistant", "content": bot_answer})

# ================ G·ª¢I √ù: L∆ØU B·∫¢NG V√Ä CH·ªà S·ªê SANG CHAT ================
# ƒê·ªÉ tab Chat c√≥ th·ªÉ "nh√¨n th·∫•y" b·∫£ng ƒë√£ x·ª≠ l√Ω khi b·∫°n b·∫•m ph√¢n t√≠ch ·ªü tab 1,
# h√£y CH√àN 2 D√íNG SAU v√†o ngay sau khi df_processed ƒë∆∞·ª£c t√≠nh trong tab_phan_tich:
# st.session_state["last_df_processed"] = df_processed
# st.session_state["last_ai_metrics"] = {
#     "tt_hien_hanh_N": thanh_toan_hien_hanh_N,
#     "tt_hien_hanh_N_1": thanh_toan_hien_hanh_N_1
# }
